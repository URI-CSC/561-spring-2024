{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "- data is loaded from `sklearn` and classes are filtered to keep only two classes (3 and 8)\n",
    "- the data is then split into train, validation, and test sets\n",
    "- the labels are converted to -1 and 1 to be used in the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "digits = load_digits()\n",
    "# filter data to only include two classes\n",
    "class1, class2 = 1, 7\n",
    "idxs = (digits.target == class1) | (digits.target == class2)\n",
    "data_x, data_y = digits.data[idxs], digits.target[idxs]\n",
    "print(data_x.shape)\n",
    "# change labels to -1 and +1\n",
    "data_y[data_y==class1] = -1\n",
    "data_y[data_y==class2] = 1\n",
    "# split the data into training, validation, and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, stratify=y_train)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a number of images from the dataset\n",
    "idxs = [random.choice(range(x_train.shape[0])) for _ in range(5)]\n",
    "fig, ax = plt.subplots(1, 5)\n",
    "for i, idx in enumerate(idxs):\n",
    "    ax[i].imshow(x_train[idx].reshape(8, 8))\n",
    "    ax[i].axis('off')\n",
    "    # add label to the image\n",
    "    ax[i].set_title(y_train[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    '''\n",
    "    A simple logistic regression model.  This class assumes all labels \n",
    "    are either -1 or 1.\n",
    "    '''\n",
    "    def __init__(self, learning_rate=0.01, max_iters=10, log_every=1):\n",
    "        '''\n",
    "        Initializes the model with learning rate and maximum iterations.\n",
    "        Args:\n",
    "            learning_rate: The learning rate for gradient descent.\n",
    "            max_iters: The maximum number of iterations for training.\n",
    "            log_every: Log the loss every `log_every` iterations.\n",
    "        '''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.log_every = log_every\n",
    "        self.weights = None\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        '''\n",
    "        Calculates the sigmoid function.\n",
    "        Args:\n",
    "            z: A NumPy array of input values.\n",
    "        Returns:\n",
    "            A NumPy array of sigmoid values.\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def __loss(self, X, y):\n",
    "        '''\n",
    "        Calculates the cost function (binary cross-entropy).\n",
    "        Args:\n",
    "            X: A NumPy array of feature vectors.\n",
    "            y: A NumPy array of target labels.\n",
    "        Returns:\n",
    "            The cross-entropy loss (scalar) and the gradient of the \n",
    "            loss with respect to weights (ndarray).\n",
    "        '''\n",
    "        # calculate a temporary value needed by both loss and gradient\n",
    "        inv = -y * (X @ self.weights)\n",
    "        loss = np.log(1 + np.exp(inv)).mean()\n",
    "        dw = self.__sigmoid(inv) * -y * X\n",
    "        dw = np.mean(dw, axis=0, keepdims=True).T\n",
    "        return loss, dw\n",
    "    \n",
    "    def __forward(self, X):\n",
    "        '''\n",
    "        Predicts the probabilities for new data.\n",
    "        Args:\n",
    "            X: A NumPy array of feature vectors.\n",
    "        Returns:\n",
    "            A NumPy array of predicted probabilities.\n",
    "        '''\n",
    "        z = X @ self.weights\n",
    "        y_pred = self.__sigmoid(z)\n",
    "        return y_pred\n",
    "    \n",
    "    def __preprocess(self, X, y):\n",
    "        '''\n",
    "        Adds a \"bias\" column to the feature vectors and reshapes\n",
    "        the target labels to be a column vector.\n",
    "        Args:\n",
    "            X: A NumPy array of feature vectors.\n",
    "            y: A NumPy array of target labels.\n",
    "        Returns:\n",
    "            The preprocessed feature vectors and target labels.\n",
    "        '''\n",
    "        newX = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "        newY = y.reshape(-1, 1)\n",
    "        return newX, newY\n",
    "\n",
    "    def train(self, X, y, x_val, y_val):\n",
    "        '''\n",
    "        Trains the model using full batch gradient descent.\n",
    "        Args:\n",
    "            X: A NumPy array of feature vectors.\n",
    "            y: A NumPy array of target labels.\n",
    "            x_val: A NumPy array of feature vectors for validation.\n",
    "            y_val: A NumPy array of target labels for validation.\n",
    "        '''\n",
    "        history = np.zeros((self.max_iters//self.log_every, 3))\n",
    "        newX, newY = self.__preprocess(X, y)\n",
    "        newX_val, newY_val = self.__preprocess(x_val, y_val)\n",
    "        # initialize weights and bias with random values\n",
    "        self.weights = np.random.rand(newX.shape[1], 1)\n",
    "        for i in range(self.max_iters):\n",
    "            # calculate gradients\n",
    "            loss, dw = self.__loss(newX, newY)\n",
    "            if (i+1) % self.log_every == 0:\n",
    "                val_loss, _ = self.__loss(newX_val, newY_val)\n",
    "                history[i//self.log_every] = (i+1, loss, val_loss)\n",
    "            # gradient descent step\n",
    "            self.weights -= (self.learning_rate * dw)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        '''\n",
    "        Evaluates the model performance using CM and accuracy.\n",
    "        Args:\n",
    "            X: A NumPy array of feature vectors.\n",
    "            y: A NumPy array of target labels.\n",
    "        Returns:\n",
    "            The confusion matrix and accuracy.\n",
    "        '''\n",
    "        newX, newY = self.__preprocess(X, y)\n",
    "        y_pred = self.__forward(newX)\n",
    "        y_pred[y_pred <= 0.5] = -1\n",
    "        y_pred[y_pred > 0.5] = 1\n",
    "        cm = confusion_matrix(newY, y_pred)\n",
    "        acc = accuracy_score(newY, y_pred)\n",
    "        \n",
    "        return cm, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model and plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(learning_rate=0.001, max_iters=200, log_every=2)\n",
    "history = model.train(x_train, y_train, x_val, y_val)\n",
    "sns.lineplot(x=history[:,0], y=history[:,1], label='train')\n",
    "sns.lineplot(x=history[:,0], y=history[:,2], label='val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
